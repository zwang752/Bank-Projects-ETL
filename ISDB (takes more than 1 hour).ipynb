{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import Request, urlopen\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_url = 'https://www.isdb.org/projects/data'\n",
    "hah='?page='\n",
    "url_list = [my_url + hah + str(a) for a in range(0,160)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table = pd.DataFrame()\n",
    "page = 1\n",
    "for url in url_list:\n",
    "    uClient = uReq(url)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    page_soup = soup(page_html, \"html.parser\")\n",
    "\n",
    "    links = [a['href'] for a in page_soup.find_all('a',href = True)]\n",
    "    num = 1\n",
    "    for link in set(links):\n",
    "        if '/projects/data/' in link:\n",
    "\n",
    "            uClient = uReq('https://www.isdb.org' + link)\n",
    "            page_html = uClient.read()\n",
    "            uClient.close()\n",
    "            page_soup = soup(page_html, \"html.parser\")\n",
    "            try:\n",
    "                title = page_soup.find_all('h1')[-1].string\n",
    "            except:\n",
    "                title=np.nan\n",
    "            try:\n",
    "                brief = page_soup.find_all('div',{'class':['field--item']})[0].text.replace('\\n',' ')\n",
    "            except:\n",
    "                brief=np.nan\n",
    "            try:\n",
    "                status = page_soup.find_all('div',{'class':['field field--name-name field--type-string field--label-hidden field--item']})[-1].text\n",
    "            except:\n",
    "                status=np.nan\n",
    "            try:\n",
    "                country = page_soup.find_all('div',{'class':['field field--name-name field--type-string field--label-hidden field--item']})[0].text\n",
    "            except:\n",
    "                country=np.nan\n",
    "            try:\n",
    "                sector = page_soup.find_all('div',{'class':['field field--name-name field--type-string field--label-hidden field--item']})[1].text\n",
    "            except:\n",
    "                sector=np.nan\n",
    "            try:\n",
    "                start = page_soup.find_all('div',{'class':['field field--name-isdb-project-start-date field--type-x-isdbproj field--label-above']})[0].text\n",
    "                s_date = start.split('\\n')[2]\n",
    "            except:\n",
    "                s_date=np.nan\n",
    "            try:\n",
    "                end = page_soup.find_all('div',{'class':['field field--name-isdb-project-end-date field--type-x-isdbproj field--label-above']})[0].text\n",
    "                e_date = end.split('\\n')[2]\n",
    "            except:\n",
    "                e_date=np.nan\n",
    "            table = pd.DataFrame([[title, brief, status, country, sector, s_date, e_date]],columns = ['Title', 'Brief', 'Status', 'Country', 'Sector', 'StartDate','EndDate'])\n",
    "            big_table=pd.concat([big_table,table],axis=0)\n",
    "            print(' page '+ str(page) + ' project ' + str(num)+ ' successfully grabbed')\n",
    "            num += 1\n",
    "        else:\n",
    "            pass\n",
    "    page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table.index=range(len(big_table))\n",
    "big_table.to_csv('ISDB_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TEST SECTION\n",
    "\n",
    "'''\n",
    "big_table = pd.DataFrame()\n",
    "num = 1\n",
    "for i in lst:\n",
    "    uClient = uReq('https://www.isdb.org' + i)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    page_soup = soup(page_html, \"html.parser\")\n",
    "    try:\n",
    "        title = page_soup.find_all('h1')[-1].string\n",
    "    except:\n",
    "        title=np.nan\n",
    "    try:\n",
    "        brief = page_soup.find_all('div',{'class':['field--item']})[0].text.replace('\\n',' ')\n",
    "    except:\n",
    "        brief=np.nan\n",
    "    try:\n",
    "        status = page_soup.find_all('div',{'class':['field field--name-name field--type-string field--label-hidden field--item']})[-1].text\n",
    "    except:\n",
    "        status=np.nan\n",
    "    try:\n",
    "        country = page_soup.find_all('div',{'class':['field field--name-name field--type-string field--label-hidden field--item']})[0].text\n",
    "    except:\n",
    "        country=np.nan\n",
    "    try:\n",
    "        sector = page_soup.find_all('div',{'class':['field field--name-name field--type-string field--label-hidden field--item']})[1].text\n",
    "    except:\n",
    "        sector=np.nan\n",
    "    try:\n",
    "        start = page_soup.find_all('div',{'class':['field field--name-isdb-project-start-date field--type-x-isdbproj field--label-above']})[0].text\n",
    "        s_date = start.split('\\n')[2]\n",
    "    except:\n",
    "        s_date=np.nan\n",
    "    try:\n",
    "        end = page_soup.find_all('div',{'class':['field field--name-isdb-project-end-date field--type-x-isdbproj field--label-above']})[0].text\n",
    "        e_date = end.split('\\n')[2]\n",
    "    except:\n",
    "        e_date=np.nan\n",
    "    table = pd.DataFrame([[title, brief, status, country, sector, s_date, e_date]],columns = ['Title', 'Brief', 'Status', 'Country', 'Sector', 'StartDate','EndDate'])\n",
    "    big_table=pd.concat([big_table,table],axis=0)\n",
    "    print('project' str(num) + ' successfully grabbed')\n",
    "    num += 1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table.index=range(len(big_table))\n",
    "big_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test\n",
    "\n",
    "'''\n",
    "#First Project to be put in a table\n",
    "web = 'https://www.isdb.org/projects/data/serial-8769'\n",
    "uClient = uReq(web)\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "page_soup = soup(page_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = page_soup.find_all('h1')[-1].string\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brief = page_soup.find_all('div',{'class':['field--item']})[0].text.replace('\\n',' ')\n",
    "brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = page_soup.find_all('div',{'class':['field field--name-name field--type-string field--label-hidden field--item']})[-1].text\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = page_soup.find_all('div',{'class':['field field--name-name field--type-string field--label-hidden field--item']})[0].text\n",
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = page_soup.find_all('div',{'class':['field field--name-name field--type-string field--label-hidden field--item']})[1].text\n",
    "sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = page_soup.find_all('div',{'class':['field field--name-isdb-project-start-date field--type-x-isdbproj field--label-above']})[0].text\n",
    "s_date = start.split('\\n')[2]\n",
    "s_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = page_soup.find_all('div',{'class':['field field--name-isdb-project-end-date field--type-x-isdbproj field--label-above']})[0].text\n",
    "e_date = end.split('\\n')[2]\n",
    "e_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame([[title, brief, status, country, sector, s_date, e_date]],columns = ['Title', 'Brief', 'Status', 'Country', 'Sector', 'StartDate','EndDate'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
